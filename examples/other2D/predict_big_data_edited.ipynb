{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of problems or questions, please first check the list of [Frequently Asked Questions (FAQ)](https://stardist.net/docs/faq.html).**\n",
    "\n",
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment creation:\n",
    "```bash\n",
    "mamba create -n stardist-napari-bioio-env -c conda-forge python=3.10 napari pyqt\n",
    "mamba activate stardist-napari-bioio-env\n",
    "mamba install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "python -m pip install \"tensorflow<2.11\"\n",
    "pip install numpy==1.26.4 # avoid having numpy <= 2.0\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\" # check if GPU is available\n",
    "pip install stardist\n",
    "pip install bioio bioio-czi\n",
    "pip install stardist-napari\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "**If you have not looked at the [regular example notebooks](../2D), please do so first.**  \n",
    "The notebooks in this folder provide further details about the inner workings of StarDist and might be useful if you want to apply it in a slightly different context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread, imwrite as imsave\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.utils.tf import keras_import\n",
    "keras = keras_import()\n",
    "\n",
    "from stardist import export_imagej_rois, random_label_cmap\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "np.random.seed(0)\n",
    "cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, **kwargs):\n",
    "    \"\"\"Plot large image at different resolutions.\"\"\"\n",
    "    fig, ax = plt.subplots(2,4, figsize=(16,8))\n",
    "    mid = [s//2 + 600 for s in img.shape[:2]]\n",
    "    for a,t,u in zip(ax.ravel(),[1,2,4,8,16,32,64,128],[16,8,4,2,1,1,1,1]):\n",
    "        sl = tuple(slice(c - s//t//2, c + s//t//2, u) for s,c in zip(img.shape[:2],mid))\n",
    "        a.imshow(img[sl], **kwargs)\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download example image in [SVS format](http://paulbourke.net/dataformats/svs/), which in this case can be read as a TIFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir  = Path('data') / 'big'\n",
    "# filename = 'image.tif'\n",
    "# url      = 'https://pathology.cancerimagingarchive.net/download/SAR/C3L-00035-21.svs'\n",
    "\n",
    "# datadir.mkdir(parents=True, exist_ok=True)\n",
    "# if not (datadir/filename).exists():\n",
    "#     keras.utils.get_file(filename, url, cache_dir=str(datadir), cache_subdir='.')\n",
    "# None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "import bioio_czi\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "path = r\"D:\\Datasets\\Julieta\\ImageAnalysis-BFX_VisiumHD\\20240604-HD-LAB5407-CaminDean\\2024_06_04__BF_0001.czi\"\n",
    "path = r\"D:\\Datasets\\Julieta\\ImageAnalysis-BFX_VisiumHD\\20240403-HD-LAB5278-YungHaeK\\2024_04_03_0001.czi\"\n",
    "\n",
    "img = BioImage(path, reader=bioio_czi.Reader)\n",
    "img = np.squeeze(img.data)\n",
    "\n",
    "image = np.squeeze(img.data)\n",
    "background_mask = np.all(np.squeeze(img.data) == [0, 0, 0], axis=-1)\n",
    "image[background_mask] = [158, 158, 158] # add light gray background to black areas\n",
    "\n",
    "\n",
    "# path = r\"C:\\Users\\mazo260d\\Documents\\GitHub\\stardist\\2024_06_04__BF_0001_with_artificial_light_BG.tiff\"\n",
    "# img = io.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = imread(str(datadir/filename))\n",
    "print(f\"image of shape {image.shape} and dtype {image.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "**NOTE:** Although this example uses 2D images, the demonstrated functionality also works for 3D StarDist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Load pretrained model for [H&E stained](https://en.wikipedia.org/wiki/H%26E_stain) images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D.from_pretrained('2D_versatile_he')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image normalization\n",
    "\n",
    "StarDist expects input images to be normalized or that a suitable `normalizer` is passed to `model.predict_instances`.  \n",
    "Typically, you'd normalize an input image directly without the need for an additional `normalizer` (commented out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = normalize(img, 1, 99.8)\n",
    "# normalizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this can be slow for large images, or even infeasible for images that do not fit in memory (e.g. via [Zarr](https://zarr.readthedocs.io), see below).  \n",
    "Hence, we do not normalize the input image `img` and instead define a custom `normalizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import Normalizer, normalize_mi_ma\n",
    "\n",
    "class MyNormalizer(Normalizer):\n",
    "    def __init__(self, mi, ma):\n",
    "            self.mi, self.ma = mi, ma\n",
    "    def before(self, x, axes):\n",
    "        return normalize_mi_ma(x, self.mi, self.ma, dtype=np.float32)\n",
    "    def after(*args, **kwargs):\n",
    "        assert False\n",
    "    @property\n",
    "    def do_after(self):\n",
    "        return False\n",
    "\n",
    "# mi, ma = np.percentile(img[::8], [1,99.8])                      # compute percentiles from low-resolution image\n",
    "# mi, ma = np.percentile(img[13000:16000,13000:16000], [1,99.8])  # compute percentiles from smaller crop\n",
    "mi, ma = 0, 255                                                   # use min and max dtype values (suitable here)\n",
    "normalizer = MyNormalizer(mi, ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block-wise prediction\n",
    "\n",
    "We could now run the prediction like this (commented out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, polys = model.predict_instances(img, normalizer=normalizer, n_tiles=(32,32,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would break down the input image into 1024 overlapping _tiles_ to be processed individually by the CNN, but the subsequent non-maximum suppression step would be run on the entire image all at once. This can be prohibitive both in terms of memory and computation requirements.\n",
    "\n",
    "Hence, we can use `model.predict_instances_big` instead, which will break up the input image into larger overlapping _blocks_, each of which is processed via `model.predict_instances`. Please see the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.predict_instances_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call `model.predict_instances_big` to run the block-wise prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, polys = model.predict_instances_big(image, axes='YXC', block_size=4096, min_overlap=128, context=128,\n",
    "                                            normalizer=normalizer, n_tiles=(4,4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show & Save\n",
    "\n",
    "Showing the predicted label image in the same way as the input image above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(labels, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** Since label ids are consecutive within each block, they are quantized to the same color when using a colormap with few colors. This allows us to visualize the blocks that have been used during prediction (left). Prediction blocks are not visible when using a suitable colormap for label images (right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (a,b) = plt.subplots(1,2, figsize=(16,16))\n",
    "a.imshow(labels[::8,::8], cmap='tab20b')\n",
    "b.imshow(labels[::8,::8], cmap=cmap)\n",
    "a.axis('off'); b.axis('off');\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from napari.utils import nbscreenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(image)\n",
    "viewer.add_labels(labels)\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results to disk as label image and/or ImageJ ROIs. (Compression highly recommended.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZIP_DEFLATED\n",
    "\n",
    "imsave(str(datadir/'labels2.tif'), labels, compression=ZIP_DEFLATED)\n",
    "# export_imagej_rois(str(datadir/'labels_roi.zip'), polys['coord'], compression=ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zarr instead of Numpy arrays for very large images\n",
    "\n",
    "If your images are too large to be loaded all at once, you can use [Zarr](https://zarr.readthedocs.io) to store and process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "# for this demo: make a zarr array copy of img\n",
    "zarr.save_array(str(datadir/'image.zarr'), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load input image as read-only Zarr array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = zarr.open(str(datadir/'image.zarr'), mode='r')\n",
    "img.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the output label image as an empty Zarr array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = zarr.open(str(datadir/'labels.zarr'), mode='w', shape=img.shape[:2], chunks=img.chunks[:2], dtype=np.int32)\n",
    "labels.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the block-wise prediction and pass `labels_out=labels` to write to the predefined Zarr array for the label image.  \n",
    "(Note: You can alternatively pass `labels_out=False` if you don't need the label image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, polys = model.predict_instances_big(img, axes='YXC', block_size=4096, min_overlap=128, context=128,\n",
    "                                            normalizer=normalizer, n_tiles=(4,4,1),\n",
    "                                            labels_out=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label image is now populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
